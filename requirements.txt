# =============================================================================
# SDXL + CLIP Reranking Pipeline - Requirements
# =============================================================================
# 
# Installation:
#   pip install -r requirements.txt
#
# For CUDA support (recommended), install PyTorch first:
#   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
#
# =============================================================================

# -----------------------------------------------------------------------------
# Core Deep Learning
# -----------------------------------------------------------------------------
torch>=2.1.0
torchvision>=0.16.0

# -----------------------------------------------------------------------------
# Diffusion Models
# -----------------------------------------------------------------------------
diffusers>=0.25.0
accelerate>=0.25.0
safetensors>=0.4.0

# -----------------------------------------------------------------------------
# Transformers & CLIP
# -----------------------------------------------------------------------------
transformers>=4.36.0
tokenizers>=0.15.0

# -----------------------------------------------------------------------------
# vLLM (for Mode B: auto-prompt from text)
# -----------------------------------------------------------------------------
# Note: vLLM requires CUDA. Skip this if running CPU-only or if you only need Mode A
vllm>=0.3.0

# -----------------------------------------------------------------------------
# Image Processing
# -----------------------------------------------------------------------------
Pillow>=10.0.0
opencv-python-headless>=4.8.0

# -----------------------------------------------------------------------------
# Visualization (for showing candidates)
# -----------------------------------------------------------------------------
matplotlib>=3.7.0

# -----------------------------------------------------------------------------
# Utilities
# -----------------------------------------------------------------------------
numpy>=1.24.0
tqdm>=4.65.0
huggingface-hub>=0.20.0

# -----------------------------------------------------------------------------
# Jupyter (if running as notebook locally)
# -----------------------------------------------------------------------------
jupyter>=1.0.0
ipywidgets>=8.0.0

# =============================================================================
# OPTIONAL DEPENDENCIES
# =============================================================================

# For 4-bit/8-bit quantization (reduces VRAM usage)
# bitsandbytes>=0.41.0

# For faster attention on supported GPUs
# xformers>=0.0.23

# For ONNX export
# optimum>=1.15.0

# =============================================================================
# NOTES
# =============================================================================
#
# Minimum VRAM Requirements:
#   - fast preset (SDXL 768px):     ~10 GB
#   - quality_1min (SDXL 1024px):   ~16 GB  
#   - quality_max (SD 3.5 Large):   ~24 GB
#   - With vLLM (Llama 8B):         +8 GB
#
# Tested with:
#   - Python 3.10, 3.11, 3.12
#   - CUDA 11.8, 12.1
#   - Ubuntu 22.04, Windows 11
#
# If you encounter issues with vLLM on Windows, consider:
#   - Using WSL2 with Ubuntu
#   - Skipping vLLM (set USE_VLLM = False) and using Mode A only
#
# =============================================================================
